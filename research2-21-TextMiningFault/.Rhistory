setwd("C:/Users/ylc/GitHub/Research/research2-21-TextMiningFault")
setwd("C:/Users/ylc/GitHub/Research/research2-21-TextMiningFault")
library(jiebaR)
### 载入数据
tf_data <- read.csv("tf.csv")
### 分词
## 建立分词器
# 建立分词器
worker <- worker(type = "mp",
encoding = "UTF-8",
bylines = TRUE)
## 对故障现象进行分词
# 提取数据
data_appearance <- tf_data[, c("编号", "故障现象")]
# 提取故障现象向量
vec_appearance <- data_appearance$故障现象
# 分词
cut_appearance <- segment(vec_appearance, worker)
# 生成一个结果数据框
cutdata_appearance <- data.frame(id = rep(data_appearance$编号, each=2), appearance = rep(data_appearance$故障现象, each=2))
# 将分词结果整理
for(i in 1:(nrow(cutdata_appearance)/2)){
cutdata_appearance$appearance[2*i] <- paste(cut_appearance[[i]], collapse = " ")
}
# 输出结果
write.csv(cutdata_appearance, "cutdata_appearance.csv", row.names = FALSE)
## 对处理方式进行分词
# 提取数据
data_solve <- tf_data[, c("编号", "处理方式")]
# 将数据整理为向量
vec_solve <- data_solve$处理方式
# 分词
cut_solve <- segment(vec_solve, worker)
# 生成一个结果数据框
cutdata_solve <- data.frame(id = rep(data_solve$编号, each=2), solve = rep(data_solve$处理方式, each=2))
# 将分词结果整理
for(i in 1:(nrow(cutdata_solve)/2)){
cutdata_solve$solve[2*i] <- paste(cut_solve[[i]], collapse = " ")
}
# 输出分词结果
write.csv(cutdata_solve, "cutdata_solve.csv", row.names = FALSE)
## 建立分词器
# 建立分词器
worker <- worker(type = "mix",
encoding = "UTF-8",
bylines = TRUE,
stop_word = STOPPATH)
## 对故障现象进行分词
# 提取数据
data_appearance <- tf_data[, c("编号", "故障现象")]
# 提取故障现象向量
vec_appearance <- data_appearance$故障现象
# 分词
cut_appearance <- segment(vec_appearance, worker)
# 生成一个结果数据框
cutdata_appearance <- data.frame(id = rep(data_appearance$编号, each=2), appearance = rep(data_appearance$故障现象, each=2))
# 将分词结果整理
for(i in 1:(nrow(cutdata_appearance)/2)){
cutdata_appearance$appearance[2*i] <- paste(cut_appearance[[i]], collapse = " ")
}
# 输出结果
write.csv(cutdata_appearance, "cutdata_appearance.csv", row.names = FALSE)
## 对处理方式进行分词
# 提取数据
data_solve <- tf_data[, c("编号", "处理方式")]
# 将数据整理为向量
vec_solve <- data_solve$处理方式
# 分词
cut_solve <- segment(vec_solve, worker)
# 生成一个结果数据框
cutdata_solve <- data.frame(id = rep(data_solve$编号, each=2), solve = rep(data_solve$处理方式, each=2))
# 将分词结果整理
for(i in 1:(nrow(cutdata_solve)/2)){
cutdata_solve$solve[2*i] <- paste(cut_solve[[i]], collapse = " ")
}
# 输出分词结果
write.csv(cutdata_solve, "cutdata_solve.csv", row.names = FALSE)
## 建立分词器
# 建立分词器
worker <- worker(type = "mix",
encoding = "UTF-8",
bylines = TRUE,
stop_word = "/stopwords/bd_hit_scu_stopwords.txt")
## 建立分词器
# 建立分词器
worker <- worker(type = "mix",
encoding = "UTF-8",
bylines = TRUE,
stop_word = "~/stopwords/bd_hit_scu_stopwords.txt")
## 建立分词器
# 建立分词器
worker <- worker(type = "mix",
encoding = "UTF-8",
bylines = TRUE,
stop_word = "~/stopwords/bd_hit_scu_stopwords.txt")
## 建立分词器
# 建立分词器
worker <- worker(type = "mix",
bylines = TRUE,
stop_word = "~/stopwords/bd_hit_scu_stopwords.txt",
encoding = "UTF-8")
## 建立分词器
# 建立分词器
worker <- worker(type = "mix",
bylines = TRUE,
stop_word = "C:/Users/ylc/GitHub/Research/research2-21-TextMiningFault/stopwords/bd_hit_scu_stopwords.txt",
encoding = "UTF-8")
## 对故障现象进行分词
# 提取数据
data_appearance <- tf_data[, c("编号", "故障现象")]
# 提取故障现象向量
vec_appearance <- data_appearance$故障现象
# 分词
cut_appearance <- segment(vec_appearance, worker)
# 生成一个结果数据框
cutdata_appearance <- data.frame(id = rep(data_appearance$编号, each=2), appearance = rep(data_appearance$故障现象, each=2))
# 将分词结果整理
for(i in 1:(nrow(cutdata_appearance)/2)){
cutdata_appearance$appearance[2*i] <- paste(cut_appearance[[i]], collapse = " ")
}
# 输出结果
write.csv(cutdata_appearance, "cutdata_appearance.csv", row.names = FALSE)
## 对处理方式进行分词
# 提取数据
data_solve <- tf_data[, c("编号", "处理方式")]
# 将数据整理为向量
vec_solve <- data_solve$处理方式
# 分词
cut_solve <- segment(vec_solve, worker)
# 生成一个结果数据框
cutdata_solve <- data.frame(id = rep(data_solve$编号, each=2), solve = rep(data_solve$处理方式, each=2))
# 将分词结果整理
for(i in 1:(nrow(cutdata_solve)/2)){
cutdata_solve$solve[2*i] <- paste(cut_solve[[i]], collapse = " ")
}
# 输出分词结果
write.csv(cutdata_solve, "cutdata_solve.csv", row.names = FALSE)
# 输出结果
write.csv(cutdata_appearance, "cutdata_appearance.csv", row.names = FALSE)
## 对处理方式进行分词
# 提取数据
data_solve <- tf_data[, c("编号", "处理方式")]
# 将数据整理为向量
vec_solve <- data_solve$处理方式
# 分词
cut_solve <- segment(vec_solve, worker)
# 生成一个结果数据框
cutdata_solve <- data.frame(id = rep(data_solve$编号, each=2), solve = rep(data_solve$处理方式, each=2))
# 将分词结果整理
for(i in 1:(nrow(cutdata_solve)/2)){
cutdata_solve$solve[2*i] <- paste(cut_solve[[i]], collapse = " ")
}
# 输出分词结果
write.csv(cutdata_solve, "cutdata_solve.csv", row.names = FALSE)
